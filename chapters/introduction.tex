\chapter{Introduction}
\label{cha:introduction}

The field of Artificial Intelligence (AI) has seen significant progress with the
advent of Large Language Models (LLMs), which leverage deep learning techniques to
process and generate human-like text. These models, built on the Transformer architecture,
have revolutionized natural language understanding and processing in many ways. In
the context of this thesis, the ability of LLMs to act autonomously on planning
and executing complex tasks has become a key research direction. Traditional planning
approaches, such as those based on Reinforcement Learning (RL) and heuristic-based
search algorithms (e.g. by using Planning Domain Definition Language (PDDL)),
have long been used to tackle structured decision-making problems. However, with
the rise of LLMs, new possibilities have emerged for solving planning problems in
a more flexible and adaptable manner.

The general problem addressed in this work revolves around planning with LLMs,
particularly in the domain of logistics tasks. Logistics problems often involve dynamic
environments where an agent must plan and execute a sequence of actions to achieve
a goal, such as picking up and delivering parcels. Classical AI planning techniques
require predefined rules, domain knowledge, and structured representations of the
world, while reinforcement learning-based approaches demand extensive training
on simulated environments. LLMs, on the other hand, introduce a novel paradigm where
reasoning and decision-making emerge from large-scale pretraining on diverse textual
data. The challenge is to determine whether LLMs can effectively function as
planners without explicit search algorithms or fine-tuned optimization
techniques.

Current research on AI planning has extensively explored methods leveraging PDDL,
which formalizes decision-making problems in a structured manner, allowing
traditional planners to compute optimal action sequences. Reinforcement Learning,
another key approach, enables agents to learn optimal strategies through trial and
error, with the final goal to maximize a reward. More recently, researchers have
investigated the potential of LLMs in planning, leveraging techniques such as Chain-of-Thought
reasoning and zero-shot or few-shot prompting to guide models toward generating coherent
plans. However, these methods still face challenges, particularly in maintaining
consistency, handling uncertainty, and ensuring goal-directed behavior in
complex environments.

This work focuses on a specific logistics task in which an agent, powered solely
by an LLM, must pick up and deliver parcels in a simulated environment while
considering uncertainty in its decision-making process. Unlike traditional planning
approaches, no additional external frameworks are integrated; instead, the LLM
itself serves as the core reasoning engine via its generative capabilities. A key
aspect of the research is the evaluation of uncertainty, using measures derived
from token log-probabilities to assess the model's confidence in its choices. By
analyzing how uncertainty impacts decision-making, we aim to identify the
strengths and weaknesses of this approach.

The objective of this study is to understand the capabilities and limitations of
LLMs when applied to planning problems, particularly in dynamic and uncertain environments.
Through systematic experiments, we aim to evaluate how well an LLM can navigate and
complete logistics tasks, whether it can adapt to varying scenarios, and how uncertainty
influences its performance. The expected results include insights into the
effectiveness of LLM-based planning, potential failure modes, and the
feasibility of using such models in real-world decision-making tasks.

This thesis is structured as follows:
\begin{itemize}
  \item \textbf{Chapter \ref{cha:background} - Background} establishes the
    theoretical foundations necessary to understand the problem space and the
    methodologies explored in the research. It covers core AI concepts, the
    evolution of LLMs, and their architecture, with a particular focus on the
    Attention mechanism and token-based uncertainty estimation. Additionally, it
    contrasts traditional planning approaches such as rule-based systems, search-based
    techniques, and Reinforcement Learning with newer LLM-driven methods, providing
    a comprehensive view of the current state of the art;

  \item \textbf{Chapter \ref{cha:experiment_setting} - Experiment Setting}
    formalizes the objective of this thesis, describing the environment used to evaluate
    our LLM-driven agent, detailing the rules of the task, the constraints imposed
    by the system as well as the functioning of the web-based environment used for
    testing, and how agent interactions are structured. It explains the decisions
    behind the model selection, highlighting the difference between uncertainty
    computation in both open source and closed source models;

  \item \textbf{Chapter \ref{cha:agent_development} - Agent Development}
    illustrates the iterative development process of the LLM-based agent, outlining
    key design decisions and the challenges encountered. It covers the evolution
    of the different implementation strategies, including the contrast between the
    final stateful and stateless agents;

  \item \textbf{Chapter \ref{cha:data_collection} - Data Collection} focuses on
    the impact of prompt design on the agent's performance and decision-making
    capabilities. It explores various prompt engineering strategies based on the
    literature, examining how different wording structures and contextual
    information influence the LLM's ability to understand and execute actions
    within the environment. Furthermore, it details how uncertainty can be
    visualized and analyzed to provide insights into the model's behavior;

  \item \textbf{Chapter \ref{cha:results_discussion} - Results Discussion} shows
    and analyze the findings from the experimental phase, highlighting key trends,
    limitations, and surprising behaviors observed in the LLM's performance. The
    discussion addresses the impact of different variables, such as map size,
    task complexity, and uncertainty estimation on the overall success rate of the
    agent. Comparative insights between stateless and stateful agents are
    provided, with their respective advantages and drawbacks;

  \item \textbf{Chapter \ref{cha:conclusions} - Conclusions} The final chapter
    summarizes the entire work, providing a synthesis of the key insights gained
    from evaluating LLMs in this scenario. It outlines current limitations and
    potential directions for future research, including improvements in uncertainty
    modeling and leveraging, hybrid approaches integrating different AI models, and
    the exploration of more structured approaches to limit the impact of uncertainty
    on decision-making.
\end{itemize}