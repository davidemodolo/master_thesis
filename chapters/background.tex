\chapter{Background}
\label{cha:background}

In this thesis, we will analyze in detail the behavior of an LLM as an agent within
a controlled environment.

Before presenting all the work carried out in detail, this chapter aims to
provide a comprehensive explanation of all the theoretical foundations necessary
to understand the steps presented in the following chapters. Starting from a brief
introduction of Artificial Intelligence just to define the boundaries in which we
are working, we will move to the core concepts. In particular, we want to
highlight what an LLM is and how it works, with a special focus on the Attention
mechanism and how the uncertainty of an LLM can be calculated. This will serve
as a basis for correctly interpreting the results analyzed in Section
\ref{cha:results_discussion}.

There will also be a broader discussion on agents in a strict sense and "LLM agents"
to better show the difference between our implementation and what is currently
being discussed over the media.

To better define the context of this thesis, we will examine the main alternative
approaches to solving a logistical problem currently studied in the literature.

\section{Artificial Intelligence}
\label{sec:artificial_intelligence}

Right now in the media, AI is being used as a synonym for Large Language Models.
However, AI is a broader concept that includes many techniques and methodologies.

\#\# Summary of different kind of AI ending with Generative Models end with NLP
history

\section{Large Language Models - LLMs}
\label{sec:large_language_models_llms}

\#\# LLMs are generative models released with the paper "Attention is All You
Need"

\subsection{LLMs' Uncertainty}
\label{sub:llms_uncertainty}

Understanding the uncertainty of an LLM is crucial to correctly interpret the text
it generates. If we ask for a yes/no question, it would make a different impact on
us reading "Yes" or "Yes - Uncertainty 49\%". Moreover, this would let us get
some kind of explainability behind these complex and opaque systems.

\#\# cite Hallucinations

\section{Agents}
\label{sec:agents}

% \begin{figure}[h!]
%   \label{fig:agent_scheme}
%   \centering
%   \includegraphics[width=.3333\textwidth]{images/Agent_Scheme.png}
%   \caption{Agent Scheme}
%   { Source: redesign of a scheme in \cite{wooldridge2002multiagent}}
% \end{figure}

As widely explained in the book "An Introduction to Multiagent Systems"
\cite{wooldridge2002multiagent}, we can summarize the definition of an agent as an
autonomous entity that perceives its environment through sensors and acts upon it
through effectors, making decisions based on its perceptions and objectives in
order to achieve specific goals.

This definition highlights several key aspects of agents:
\begin{itemize}
  \item Autonomy: Agents operate without direct human intervention, controlling their
    own actions.

  \item Perception and Action: They interact with the environment via sensors (perception)
    and effectors (action execution).

  \item Decision-making: Agents select actions based on their internal model, goals,
    and the state of the environment.

  \item Non-determinism and Adaptability: Since environments are generally non-deterministic,
    agents must be prepared for uncertainty and potential failures in action execution.

  \item Preconditions and Constraints: Actions are subject to certain conditions
    that must be met for successful execution.
\end{itemize}

Thus, an agent's fundamental challenge is deciding which actions to perform in order
to best satisfy its objectives, given the constraints and uncertainties of its
environment.

\begin{figure}[h!]
  \centering
  \begin{tikzpicture}[
    node distance=2cm, % Distance between nodes
  ]
    \node[
      rectangle,
      minimum width=3cm,
      minimum height=1cm,
      text centered,
      draw=black,
      fill={rgb,255:red,5; green,91; blue,0},
      text=white
    ] (agent) {Agent};
    \node[
      rectangle,
      minimum width=3cm,
      minimum height=1cm,
      text centered,
      draw=black,
      below of=agent,
      fill={rgb,255:red,171; green,171; blue,171},
      text=white
    ] (env) {Environment};

    % First arrow (Action) slightly shifted right
    \draw[thick, ->, >=stealth]
      (agent.south)
      ++(0.5,0) -- ++(0,-1)
      node[midway, right] {Action};

    % Second arrow (Observation) slightly shifted left
    \draw[thick, ->, >=stealth]
      (env.north)
      ++(-0.5,0) -- ++(0,1)
      node[midway, left] {Observation};
  \end{tikzpicture}
  \caption{Agent Design Scheme}
  { Source: redesign of a scheme in \cite{wooldridge2002multiagent}} \label{fig:agent_scheme}
\end{figure}

As shown in Figure \ref{fig:agent_scheme}, an agent is some entity that
perceives the environment and reacts to it. The environment can be anything from
a simple thermostat to a complex system like a self-driving car. The idea is
that the agent is able to react to a change in the environment and take actions
to achieve its goals.

We will analyze in detail the prompts and the choices in the Chapter
\ref{cha:data_collection} Section \ref{sec:prompts}, but to give an some kind of
help to align with the definition above, we can map some of its concept to what
this thesis will analyze:
\begin{itemize}
  \item Perception and Action: what the server sends about the current state of
    the environment can be seen as the perception of the agent, while the action
    it can take will be given in the prompt in a specific way.

  \item Decision-making: the decision-making process will be the generation of
    the text by the LLM, weighted by the uncertainty.

  \item Non-determinism and Adaptability: to emulate the non-determinism of the
    environment, the state received by the server will be used "raw" in the prompt,
    without any hard processing or parsing.

  \item Preconditions and Constraints: living in a "limited" map with a fixed
    number of cells, is itself a constraint the agent must consider.
\end{itemize}

\subsection{BDI Architecture}
\label{sub:bdi_architecture}

The Belief-Desire-Intention (BDI) architecture is a widely adopted framework in artificial
intelligence (AI) for modeling rational agents. It was formally developed by Rao
and Georgeff in 1995 \cite{bdi-icmas95} and has been implemented in several
architectures, including PRS (1987), dMARS (1998), JAM (1999), Jack (2001), and JADEX
(2005). BDI provides a structured approach to practical reasoning, allowing agents
to function effectively in dynamic and unpredictable environments.

\subsubsection{Core Components of BDI}
BDI agents operate based on three key components:
\begin{itemize}
  \item Belief: Represents the agent’s knowledge about the world, including past
    events and observations. Given the agent's local perception and limited
    computational resources, beliefs act as cached, imperfect information rather
    than absolute knowledge

  \item Desire (Goals): Defines the agent’s objectives or preferred end states, such
    as "desiring to graduate." Desires help in justifying why an agent takes
    specific actions and enable reasoning about goal interactions, particularly in
    failure recovery scenarios

  \item Intention: Represents the commitments of an agent toward achieving
    specific goals through selected plans. Intentions provide structure by ensuring
    persistence and internal consistency, allowing for incremental planning and
    adaptation in real-time. They also serve as a means of coordinating multiple
    agents in distributed systems.
\end{itemize}

\subsubsection{BDI in Practical AI Applications}

BDI has been extensively used in fields like robotics, automated planning, and
multi-agent systems. For instance, JADEX is a popular Java-based BDI framework
used in simulations and decision-making applications.

\section{State of the Art}
\label{sec:state_of_the_art}

A logistic problem is a typical problem in the field of AI, and there are
several approaches to solve it. In this section, we will analyze the main
alternatives to LLMs in the literature and highlight the core differences
between them and our approach.

\begin{quotation}
  This is a longer blockquote that may span multiple paragraphs. It is indented
  on both sides.
\end{quotation}

\subsection{PDDL Based Solution}
\begin{blockquote}
  \textbf{Planning Domain Definition Language} (PDDL) is a human-readable format
  for problems in automated planning that gives a description of the possible
  states of the world, a description of the set of possible actions, a specific
  initial state of the world, and a specific set of desired goals.

  \emph{Source: Wikipedia \cite{wiki-pddl}}
\end{blockquote}

The core difference between a PDDL-based solution and ours lays in the
definition of PDDL. In a PDDL-based solution, the problem is defined in a formal
language, and the planner is responsible for finding a sequence of actions that lead
from the initial state to the goal state.

This approach is time-intensive and not suitable for real-time applications,
since starting from the initial state, the planner has to travel the graph of all
possible states until it finds a state contained in the possible goal states (with
the use of some heuristics).

\begin{lstlisting}[
  caption={Domain file example for a bit toggle problem},
  label={lst:domain_file_toggle_bits},
  backgroundcolor=\color{code-bg},
  numbers=left,
  keywordstyle=\color{primary}\bfseries,
  morekeywords={define, requirements, predicates, action}
]
(define (domain bit-toggle)
  (:requirements :strips :negative-preconditions)
  (:predicates
    (bit ?b)                       ; predicate meaning
                                   ; bit ?b is set (true)
  )

  (:action set-bit
    :parameters (?b)
    :precondition (not (bit ?b))   ; can only set a bit if
                                   ; it is not already set
    :effect (bit ?b)               ; setting the bit to true
  )

  (:action unset-bit
    :parameters (?b)
    :precondition (bit ?b)         ; can only unset a bit if
                                   ; it is currently set
    :effect (not (bit ?b))         ; setting the bit to false
  )
)
\end{lstlisting}

\begin{lstlisting}[
  caption={Problem file example for a bit toggle problem},
  label={lst:problem_file_toggle_bits},
  backgroundcolor=\color{code-bg},
  numbers=left,
  keywordstyle=\color{primary}\bfseries,
  morekeywords={define, init, goal}
]
(define (problem bit-toggle-full-problem)
  (:domain bit-toggle-full)
  (:objects
     b1 b2 b3
  )
  (:init)                          ; Initially all bits are unset (false)

  (:goal                           ; It can be any combination of T/F
     (and (bit b1) (bit b2) (not(bit b3)))
  )
)
\end{lstlisting}
\noindent
\begin{minipage}{0.33\textwidth}
  \centering
  \begin{tikzpicture}[nodes={draw, circle, minimum size=10mm, inner sep=0pt}]
    % First plot
    \node (00) at (0,0) [fill=primary, text=white] {00};
    \node (01) at (2,1) [fill=code-bg] {01};
    \node (10) at (2,-1) [fill=code-bg] {10};
    \node (11)
      at
      (4,0)
      [fill=code-bg, thick, draw=primary, line width=1mm]
      {11};
    \draw (00) -- (01);
    \draw (00) -- (10);
    \draw (01) -- (11);
    \draw (10) -- (11);
  \end{tikzpicture}

  \vspace{1cm} % Space between first and second plot

  \begin{tikzpicture}[nodes={draw, circle, minimum size=10mm, inner sep=0pt}]
    % Second plot
    \node (000) at (0,0) [fill=primary, text=white] {000};
    \node (001) at (2,1) [fill=code-bg] {001};
    \node (010) at (2,-1) [fill=code-bg] {010};
    \node (011) at (4,0) [fill=code-bg] {011};
    \node (100) at (2,3) [fill=code-bg] {100};
    \node (101) at (4,2) [fill=code-bg] {101};
    \node (110)
      at
      (4,4)
      [fill=code-bg, thick, draw=primary, line width=1mm]
      {110};
    \node (111) at (6,3) [fill=code-bg] {111};
    \draw (000) -- (001);
    \draw (000) -- (010);
    \draw (000) -- (100);
    \draw (001) -- (011);
    \draw (001) -- (101);
    \draw (010) -- (011);
    \draw (010) -- (110);
    \draw (100) -- (101);
    \draw (100) -- (110);
    \draw (011) -- (111);
    \draw (101) -- (111);
    \draw (110) -- (111);
  \end{tikzpicture}
\end{minipage}
\hfill
\begin{minipage}{0.66\textwidth}
  \centering
  \begin{tikzpicture}[nodes={draw, circle, minimum size=10mm, inner sep=0pt}]
    % Third plot
    \node (0000) at (0,0) [fill=primary, text=white] {0000};
    \node (0001) at (2,1) [fill=code-bg] {0001};
    \node (0010) at (2,-1) [fill=code-bg] {0010};
    \node (0011) at (4,0) [fill=code-bg] {0011};
    \node (0100) at (2,3) [fill=code-bg] {0100};
    \node (0101) at (4,2) [fill=code-bg] {0101};
    \node (0110) at (4,-2) [fill=code-bg] {0110};
    \node (0111) at (6,0) [fill=code-bg] {0111};
    \node (1000) at (2,5) [fill=code-bg] {1000};
    \node (1001) at (4,4) [fill=code-bg] {1001};
    \node (1010) at (4,6) [fill=code-bg] {1010};
    \node (1011) at (6,5) [fill=code-bg] {1011};
    \node (1100) at (4,8) [fill=code-bg] {1100};
    \node (1101) at (6,7) [fill=code-bg] {1101};
    \node (1110)
      at
      (6,9)
      [fill=code-bg, thick, draw=primary, line width=1mm]
      {1110};
    \node (1111) at (8,8) [fill=code-bg] {1111};
    \draw (0000) -- (0001);
    \draw (0000) -- (0010);
    \draw (0000) -- (0100);
    \draw (0000) -- (1000);
    \draw (0001) -- (0011);
    \draw (0001) -- (0101);
    \draw (0001) -- (1001);
    \draw (0010) -- (0011);
    \draw (0010) -- (0110);
    \draw (0010) -- (1010);
    \draw (0011) -- (0111);
    \draw (0011) -- (1011);
    \draw (0100) -- (0101);
    \draw (0100) -- (0110);
    \draw (0100) -- (1100);
    \draw (0101) -- (0111);
    \draw (0101) -- (1101);
    \draw (0110) -- (0111);
    \draw (0110) -- (1110);
    \draw (0111) -- (1111);
    \draw (1000) -- (1001);
    \draw (1000) -- (1010);
    \draw (1000) -- (1100);
    \draw (1001) -- (1011);
    \draw (1001) -- (1101);
    \draw (1010) -- (1011);
    \draw (1010) -- (1110);
    \draw (1011) -- (1111);
    \draw (1100) -- (1101);
    \draw (1100) -- (1110);
    \draw (1101) -- (1111);
    \draw (1110) -- (1111);
  \end{tikzpicture}
\end{minipage}

\begin{figure}[h!]
  \centering
  \subfloat[
  \centering
  label 1]{{ \begin{tikzpicture}\begin{axis}[ title={Arcs over number of bits}, xlabel={Bits}, ylabel={Arcs}, width=7cm, height=7cm, xmin=2, xmax=16, ymin=4, ymax=550000, xtick={2,3,4,5,6,7,8,9,10,11,12,13,14,15,16}, ytick={11264,53248,114688,245760, 524288}, legend pos=north west, ymajorgrids=true, grid style=dashed, ]\addplot[ color=primary, mark=square, ] coordinates { (2,4)(3,12)(4,32)(5,80)(6,192)(7,448)(8,1024)(9,2304)(10,5120)(11,11264)(12,24576)(13,53248)(14,114688)(15,245760)(16,524288) }; \legend{Number of arcs}\end{axis}\end{tikzpicture} }}
  \qquad \subfloat[
  \centering
  label 1]{{ \begin{tikzpicture}\begin{semilogyaxis}[ title={Arcs over number of bits (Log Scale)}, xlabel={Bits}, ylabel={Arcs}, width=7cm, height=7cm, xmin=2, xmax=16, ymin=4, ymax=550000, xtick={2,3,4,5,6,7,8,9,10,11,12,13,14,15,16}, ytick={4,10,100,1000,10000,100000}, legend pos=north west, ymajorgrids=true, grid style=dashed, ] \addplot[ color=primary, mark=square, ] coordinates { (2,4)(3,12)(4,32)(5,80)(6,192)(7,448)(8,1024)(9,2304)(10,5120)(11,11264)(12,24576)(13,53248)(14,114688)(15,245760)(16,524288) }; \legend{Number of arcs}\end{semilogyaxis}\end{tikzpicture} }}
  \caption{Arcs per Bit}
\end{figure}

With the increasing number of variables (actions, objects), the number of
possible states blows up. In fact, as we can see in Figure X, with just a pre-condition
and a goal, the number of possible states grows exponentially.

However, it is more explainable and efficient in limited environments, since all
the information is explicitly defined by the user.

An example of a similar problem solved using PDDL can be found in the paper ``An
AI Planning Approach to Emergency Material Scheduling Using Numerical PDDL" by Yang
et al. \cite{Yang2022}.

PDDL: pro (explainable, efficienza in ambienti limitati) e contro (time intensive,
non c'è adattamento, in un problema di dimensioni moderate è quasi impossibile usarlo
in real time)

Reinforcement Learning: pro (efficace, si può adattare all'ambiente che cambia) e
contro (convergenza ad un local minima nella reward function, no explainability,
costoso da allenare)

Agenti LLM (es. o1 di OpenAI): introduzione a temi emergenti come il Chain of
Thought, sottolineando come viene eseguito il reasoning e cosa differisce dal mio
approccio

Planning in LLM